{"ast":null,"code":"import { __assign } from \"tslib\";\nimport { invariant, InvariantError } from 'ts-invariant';\nimport { equal } from '@wry/equality';\nimport { createFragmentMap, getFragmentFromSelection, getDefaultValues, getFragmentDefinitions, getOperationDefinition, getTypenameFromResult, makeReference, isField, resultKeyNameFromField, isReference, shouldInclude, hasDirectives, cloneDeep } from \"../../utilities/index.js\";\nimport { makeProcessedFieldsMerger, fieldNameFromStoreName, storeValueIsStoreObject } from \"./helpers.js\";\n;\n\nvar StoreWriter = function () {\n  function StoreWriter(cache, reader) {\n    this.cache = cache;\n    this.reader = reader;\n  }\n\n  StoreWriter.prototype.writeToStore = function (_a) {\n    var query = _a.query,\n        result = _a.result,\n        dataId = _a.dataId,\n        store = _a.store,\n        variables = _a.variables;\n    var operationDefinition = getOperationDefinition(query);\n    var merger = makeProcessedFieldsMerger();\n    variables = __assign(__assign({}, getDefaultValues(operationDefinition)), variables);\n    var ref = this.processSelectionSet({\n      result: result || Object.create(null),\n      dataId: dataId,\n      selectionSet: operationDefinition.selectionSet,\n      mergeTree: {\n        map: new Map()\n      },\n      context: {\n        store: store,\n        written: Object.create(null),\n        merge: function (existing, incoming) {\n          return merger.merge(existing, incoming);\n        },\n        variables: variables,\n        varString: JSON.stringify(variables),\n        fragmentMap: createFragmentMap(getFragmentDefinitions(query))\n      }\n    });\n\n    if (!isReference(ref)) {\n      throw process.env.NODE_ENV === \"production\" ? new InvariantError(7) : new InvariantError(\"Could not identify object \" + JSON.stringify(result));\n    }\n\n    store.retain(ref.__ref);\n    return ref;\n  };\n\n  StoreWriter.prototype.processSelectionSet = function (_a) {\n    var _this = this;\n\n    var dataId = _a.dataId,\n        result = _a.result,\n        selectionSet = _a.selectionSet,\n        context = _a.context,\n        mergeTree = _a.mergeTree;\n    var policies = this.cache.policies;\n\n    var _b = policies.identify(result, selectionSet, context.fragmentMap),\n        id = _b[0],\n        keyObject = _b[1];\n\n    dataId = dataId || id;\n\n    if (\"string\" === typeof dataId) {\n      var sets = context.written[dataId] || (context.written[dataId] = []);\n      var ref = makeReference(dataId);\n      if (sets.indexOf(selectionSet) >= 0) return ref;\n      sets.push(selectionSet);\n\n      if (this.reader && this.reader.isFresh(result, ref, selectionSet, context)) {\n        return ref;\n      }\n    }\n\n    var incomingFields = Object.create(null);\n\n    if (keyObject) {\n      incomingFields = context.merge(incomingFields, keyObject);\n    }\n\n    var typename = dataId && policies.rootTypenamesById[dataId] || getTypenameFromResult(result, selectionSet, context.fragmentMap) || dataId && context.store.get(dataId, \"__typename\");\n\n    if (\"string\" === typeof typename) {\n      incomingFields.__typename = typename;\n    }\n\n    var workSet = new Set(selectionSet.selections);\n    workSet.forEach(function (selection) {\n      var _a;\n\n      if (!shouldInclude(selection, context.variables)) return;\n\n      if (isField(selection)) {\n        var resultFieldKey = resultKeyNameFromField(selection);\n        var value = result[resultFieldKey];\n\n        if (typeof value !== 'undefined') {\n          var storeFieldName = policies.getStoreFieldName({\n            typename: typename,\n            fieldName: selection.name.value,\n            field: selection,\n            variables: context.variables\n          });\n          var childTree = getChildMergeTree(mergeTree, storeFieldName);\n\n          var incomingValue = _this.processFieldValue(value, selection, context, childTree);\n\n          var childTypename = selection.selectionSet && context.store.getFieldValue(incomingValue, \"__typename\") || void 0;\n          var merge = policies.getMergeFunction(typename, selection.name.value, childTypename);\n\n          if (merge) {\n            childTree.info = {\n              field: selection,\n              typename: typename,\n              merge: merge\n            };\n          } else {\n            maybeRecycleChildMergeTree(mergeTree, storeFieldName);\n          }\n\n          incomingFields = context.merge(incomingFields, (_a = {}, _a[storeFieldName] = incomingValue, _a));\n        } else if (policies.usingPossibleTypes && !hasDirectives([\"defer\", \"client\"], selection)) {\n          throw process.env.NODE_ENV === \"production\" ? new InvariantError(8) : new InvariantError(\"Missing field '\" + resultFieldKey + \"' in \" + JSON.stringify(result, null, 2).substring(0, 100));\n        }\n      } else {\n        var fragment = getFragmentFromSelection(selection, context.fragmentMap);\n\n        if (fragment && policies.fragmentMatches(fragment, typename, result, context.variables)) {\n          fragment.selectionSet.selections.forEach(workSet.add, workSet);\n        }\n      }\n    });\n\n    if (\"string\" === typeof dataId) {\n      var entityRef_1 = makeReference(dataId);\n\n      if (mergeTree.map.size) {\n        incomingFields = this.applyMerges(mergeTree, entityRef_1, incomingFields, context);\n      }\n\n      if (process.env.NODE_ENV !== \"production\") {\n        var hasSelectionSet_1 = function (storeFieldName) {\n          return fieldsWithSelectionSets_1.has(fieldNameFromStoreName(storeFieldName));\n        };\n\n        var fieldsWithSelectionSets_1 = new Set();\n        workSet.forEach(function (selection) {\n          if (isField(selection) && selection.selectionSet) {\n            fieldsWithSelectionSets_1.add(selection.name.value);\n          }\n        });\n\n        var hasMergeFunction_1 = function (storeFieldName) {\n          var childTree = mergeTree.map.get(storeFieldName);\n          return Boolean(childTree && childTree.info && childTree.info.merge);\n        };\n\n        Object.keys(incomingFields).forEach(function (storeFieldName) {\n          if (hasSelectionSet_1(storeFieldName) && !hasMergeFunction_1(storeFieldName)) {\n            warnAboutDataLoss(entityRef_1, incomingFields, storeFieldName, context.store);\n          }\n        });\n      }\n\n      context.store.merge(dataId, incomingFields);\n      return entityRef_1;\n    }\n\n    return incomingFields;\n  };\n\n  StoreWriter.prototype.processFieldValue = function (value, field, context, mergeTree) {\n    var _this = this;\n\n    if (!field.selectionSet || value === null) {\n      return process.env.NODE_ENV === 'production' ? value : cloneDeep(value);\n    }\n\n    if (Array.isArray(value)) {\n      return value.map(function (item, i) {\n        var value = _this.processFieldValue(item, field, context, getChildMergeTree(mergeTree, i));\n\n        maybeRecycleChildMergeTree(mergeTree, i);\n        return value;\n      });\n    }\n\n    return this.processSelectionSet({\n      result: value,\n      selectionSet: field.selectionSet,\n      context: context,\n      mergeTree: mergeTree\n    });\n  };\n\n  StoreWriter.prototype.applyMerges = function (mergeTree, existing, incoming, context, getStorageArgs) {\n    var _a;\n\n    var _this = this;\n\n    if (mergeTree.map.size && !isReference(incoming)) {\n      var e_1 = !Array.isArray(incoming) && (isReference(existing) || storeValueIsStoreObject(existing)) ? existing : void 0;\n      var i_1 = incoming;\n\n      if (e_1 && !getStorageArgs) {\n        getStorageArgs = [isReference(e_1) ? e_1.__ref : e_1];\n      }\n\n      var changedFields_1;\n\n      var getValue_1 = function (from, name) {\n        return Array.isArray(from) ? typeof name === \"number\" ? from[name] : void 0 : context.store.getFieldValue(from, String(name));\n      };\n\n      mergeTree.map.forEach(function (childTree, storeFieldName) {\n        if (getStorageArgs) {\n          getStorageArgs.push(storeFieldName);\n        }\n\n        var eVal = getValue_1(e_1, storeFieldName);\n        var iVal = getValue_1(i_1, storeFieldName);\n\n        var aVal = _this.applyMerges(childTree, eVal, iVal, context, getStorageArgs);\n\n        if (aVal !== iVal) {\n          changedFields_1 = changedFields_1 || new Map();\n          changedFields_1.set(storeFieldName, aVal);\n        }\n\n        if (getStorageArgs) {\n          invariant(getStorageArgs.pop() === storeFieldName);\n        }\n      });\n\n      if (changedFields_1) {\n        incoming = Array.isArray(i_1) ? i_1.slice(0) : __assign({}, i_1);\n        changedFields_1.forEach(function (value, name) {\n          incoming[name] = value;\n        });\n      }\n    }\n\n    if (mergeTree.info) {\n      return this.cache.policies.runMergeFunction(existing, incoming, mergeTree.info, context, getStorageArgs && (_a = context.store).getStorage.apply(_a, getStorageArgs));\n    }\n\n    return incoming;\n  };\n\n  return StoreWriter;\n}();\n\nexport { StoreWriter };\nvar emptyMergeTreePool = [];\n\nfunction getChildMergeTree(_a, name) {\n  var map = _a.map;\n\n  if (!map.has(name)) {\n    map.set(name, emptyMergeTreePool.pop() || {\n      map: new Map()\n    });\n  }\n\n  return map.get(name);\n}\n\nfunction maybeRecycleChildMergeTree(_a, name) {\n  var map = _a.map;\n  var childTree = map.get(name);\n\n  if (childTree && !childTree.info && !childTree.map.size) {\n    emptyMergeTreePool.push(childTree);\n    map.delete(name);\n  }\n}\n\nvar warnings = new Set();\n\nfunction warnAboutDataLoss(existingRef, incomingObj, storeFieldName, store) {\n  var getChild = function (objOrRef) {\n    var child = store.getFieldValue(objOrRef, storeFieldName);\n    return typeof child === \"object\" && child;\n  };\n\n  var existing = getChild(existingRef);\n  if (!existing) return;\n  var incoming = getChild(incomingObj);\n  if (!incoming) return;\n  if (isReference(existing)) return;\n  if (equal(existing, incoming)) return;\n\n  if (Object.keys(existing).every(function (key) {\n    return store.getFieldValue(incoming, key) !== void 0;\n  })) {\n    return;\n  }\n\n  var parentType = store.getFieldValue(existingRef, \"__typename\") || store.getFieldValue(incomingObj, \"__typename\");\n  var fieldName = fieldNameFromStoreName(storeFieldName);\n  var typeDotName = parentType + \".\" + fieldName;\n  if (warnings.has(typeDotName)) return;\n  warnings.add(typeDotName);\n  var childTypenames = [];\n\n  if (!Array.isArray(existing) && !Array.isArray(incoming)) {\n    [existing, incoming].forEach(function (child) {\n      var typename = store.getFieldValue(child, \"__typename\");\n\n      if (typeof typename === \"string\" && !childTypenames.includes(typename)) {\n        childTypenames.push(typename);\n      }\n    });\n  }\n\n  process.env.NODE_ENV === \"production\" || invariant.warn(\"Cache data may be lost when replacing the \" + fieldName + \" field of a \" + parentType + \" object.\\n\\nTo address this problem (which is not a bug in Apollo Client), \" + (childTypenames.length ? \"either ensure all objects of type \" + childTypenames.join(\" and \") + \" have an ID or a custom merge function, or \" : \"\") + \"define a custom merge function for the \" + typeDotName + \" field, so InMemoryCache can safely merge these objects:\\n\\n  existing: \" + JSON.stringify(existing).slice(0, 1000) + \"\\n  incoming: \" + JSON.stringify(incoming).slice(0, 1000) + \"\\n\\nFor more information about these options, please refer to the documentation:\\n\\n  * Ensuring entity objects have IDs: https://go.apollo.dev/c/generating-unique-identifiers\\n  * Defining custom merge functions: https://go.apollo.dev/c/merging-non-normalized-objects\\n\");\n}","map":{"version":3,"sources":["../../../src/cache/inmemory/writeToStore.ts"],"names":[],"mappings":";AACA,SAAS,SAAT,EAAoB,cAApB,QAA0C,cAA1C;AACA,SAAS,KAAT,QAAsB,eAAtB;AAEA,SACE,iBADF,EAGE,wBAHF,EAIE,gBAJF,EAKE,sBALF,EAME,sBANF,EAOE,qBAPF,EAQE,aARF,EASE,OATF,EAUE,sBAVF,EAcE,WAdF,EAeE,aAfF,EAgBE,aAhBF,EAiBE,SAjBF,QAkBO,0BAlBP;AAqBA,SAAS,yBAAT,EAAoC,sBAApC,EAA4D,uBAA5D,QAA2F,cAA3F;AAYC;;AAkBD,IAAA,WAAA,GAAA,YAAA;AACE,WAAA,WAAA,CACkB,KADlB,EAEU,MAFV,EAE8B;AADZ,SAAA,KAAA,GAAA,KAAA;AACR,SAAA,MAAA,GAAA,MAAA;AACN;;AAgBG,EAAA,WAAA,CAAA,SAAA,CAAA,YAAA,GAAP,UAAoB,EAApB,EAMsB;QALpB,KAAK,GAAA,EAAA,CAAA,K;QACL,MAAM,GAAA,EAAA,CAAA,M;QACN,MAAM,GAAA,EAAA,CAAA,M;QACN,KAAK,GAAA,EAAA,CAAA,K;QACL,SAAS,GAAA,EAAA,CAAA,S;AAET,QAAM,mBAAmB,GAAG,sBAAsB,CAAC,KAAD,CAAlD;AACA,QAAM,MAAM,GAAG,yBAAyB,EAAxC;AAEA,IAAA,SAAS,GAAA,QAAA,CAAA,QAAA,CAAA,EAAA,EACJ,gBAAgB,CAAC,mBAAD,CADZ,CAAA,EAEJ,SAFI,CAAT;AAKA,QAAM,GAAG,GAAG,KAAK,mBAAL,CAAyB;AACnC,MAAA,MAAM,EAAE,MAAM,IAAI,MAAM,CAAC,MAAP,CAAc,IAAd,CADiB;AAEnC,MAAA,MAAM,EAAA,MAF6B;AAGnC,MAAA,YAAY,EAAE,mBAAmB,CAAC,YAHC;AAInC,MAAA,SAAS,EAAE;AAAE,QAAA,GAAG,EAAE,IAAI,GAAJ;AAAP,OAJwB;AAKnC,MAAA,OAAO,EAAE;AACP,QAAA,KAAK,EAAA,KADE;AAEP,QAAA,OAAO,EAAE,MAAM,CAAC,MAAP,CAAc,IAAd,CAFF;AAGP,QAAA,KAAK,EAAL,UAAS,QAAT,EAAsB,QAAtB,EAAiC;AAC/B,iBAAO,MAAM,CAAC,KAAP,CAAa,QAAb,EAAuB,QAAvB,CAAP;AACD,SALM;AAMP,QAAA,SAAS,EAAA,SANF;AAOP,QAAA,SAAS,EAAE,IAAI,CAAC,SAAL,CAAe,SAAf,CAPJ;AAQP,QAAA,WAAW,EAAE,iBAAiB,CAAC,sBAAsB,CAAC,KAAD,CAAvB;AARvB;AAL0B,KAAzB,CAAZ;;AAiBA,QAAI,CAAC,WAAW,CAAC,GAAD,CAAhB,EAAuB;AACrB,YAAM,OAAI,CAAA,GAAJ,CAAI,QAAJ,KAAmB,YAAnB,GAAmB,IAAA,cAAA,CAAkC,CAAlC,CAAnB,GAA8D,IAAC,cAAD,CAAY,+BAAA,IAAA,CAAA,SAAA,CAAA,MAAA,CAAZ,CAApE;AACD;;AAOD,IAAA,KAAK,CAAC,MAAN,CAAa,GAAG,CAAC,KAAjB;AAEA,WAAO,GAAP;AACD,GA5CM;;AA8CC,EAAA,WAAA,CAAA,SAAA,CAAA,mBAAA,GAAR,UAA4B,EAA5B,EAQ6B;AAR7B,QAAA,KAAA,GAAA,IAAA;;QACE,MAAM,GAAA,EAAA,CAAA,M;QACN,MAAM,GAAA,EAAA,CAAA,M;QACN,YAAY,GAAA,EAAA,CAAA,Y;QACZ,OAAO,GAAA,EAAA,CAAA,O;QAGP,SAAS,GAAA,EAAA,CAAA,S;AAED,QAAA,QAAQ,GAAK,KAAK,KAAL,CAAL,QAAR;;AAIF,QAAA,EAAA,GAAkB,QAAQ,CAAC,QAAT,CACtB,MADsB,EACd,YADc,EACA,OAAO,CAAC,WADR,CAAlB;AAAA,QAAC,EAAE,GAAA,EAAA,CAAA,CAAA,CAAH;AAAA,QAAK,SAAS,GAAA,EAAA,CAAA,CAAA,CAAd;;AAKN,IAAA,MAAM,GAAG,MAAM,IAAI,EAAnB;;AAEA,QAAI,aAAa,OAAO,MAAxB,EAAgC;AAM9B,UAAM,IAAI,GAAG,OAAO,CAAC,OAAR,CAAgB,MAAhB,MAA4B,OAAO,CAAC,OAAR,CAAgB,MAAhB,IAA0B,EAAtD,CAAb;AACA,UAAM,GAAG,GAAG,aAAa,CAAC,MAAD,CAAzB;AACA,UAAI,IAAI,CAAC,OAAL,CAAa,YAAb,KAA8B,CAAlC,EAAqC,OAAO,GAAP;AACrC,MAAA,IAAI,CAAC,IAAL,CAAU,YAAV;;AAOA,UAAI,KAAK,MAAL,IAAe,KAAK,MAAL,CAAY,OAAZ,CACjB,MADiB,EAEjB,GAFiB,EAGjB,YAHiB,EAIjB,OAJiB,CAAnB,EAKG;AACD,eAAO,GAAP;AACD;AACF;;AAID,QAAI,cAAc,GAAgB,MAAM,CAAC,MAAP,CAAc,IAAd,CAAlC;;AAIA,QAAI,SAAJ,EAAe;AACb,MAAA,cAAc,GAAG,OAAO,CAAC,KAAR,CAAc,cAAd,EAA8B,SAA9B,CAAjB;AACD;;AAKD,QAAM,QAAQ,GACX,MAAM,IAAI,QAAQ,CAAC,iBAAT,CAA2B,MAA3B,CAAX,IACA,qBAAqB,CAAC,MAAD,EAAS,YAAT,EAAuB,OAAO,CAAC,WAA/B,CADrB,IAEC,MAAM,IAAI,OAAO,CAAC,KAAR,CAAc,GAAd,CAAkB,MAAlB,EAA0B,YAA1B,CAHb;;AAKA,QAAI,aAAa,OAAO,QAAxB,EAAkC;AAChC,MAAA,cAAc,CAAC,UAAf,GAA4B,QAA5B;AACD;;AAED,QAAM,OAAO,GAAG,IAAI,GAAJ,CAAQ,YAAY,CAAC,UAArB,CAAhB;AAEA,IAAA,OAAO,CAAC,OAAR,CAAgB,UAAA,SAAA,EAAS;;;AACvB,UAAI,CAAC,aAAa,CAAC,SAAD,EAAY,OAAO,CAAC,SAApB,CAAlB,EAAkD;;AAElD,UAAI,OAAO,CAAC,SAAD,CAAX,EAAwB;AACtB,YAAM,cAAc,GAAG,sBAAsB,CAAC,SAAD,CAA7C;AACA,YAAM,KAAK,GAAG,MAAM,CAAC,cAAD,CAApB;;AAEA,YAAI,OAAO,KAAP,KAAiB,WAArB,EAAkC;AAChC,cAAM,cAAc,GAAG,QAAQ,CAAC,iBAAT,CAA2B;AAChD,YAAA,QAAQ,EAAA,QADwC;AAEhD,YAAA,SAAS,EAAE,SAAS,CAAC,IAAV,CAAe,KAFsB;AAGhD,YAAA,KAAK,EAAE,SAHyC;AAIhD,YAAA,SAAS,EAAE,OAAO,CAAC;AAJ6B,WAA3B,CAAvB;AAOA,cAAM,SAAS,GAAG,iBAAiB,CAAC,SAAD,EAAY,cAAZ,CAAnC;;AAEA,cAAI,aAAa,GACf,KAAI,CAAC,iBAAL,CAAuB,KAAvB,EAA8B,SAA9B,EAAyC,OAAzC,EAAkD,SAAlD,CADF;;AAGA,cAAM,aAAa,GAAG,SAAS,CAAC,YAAV,IACjB,OAAO,CAAC,KAAR,CAAc,aAAd,CAAoC,aAApC,EAAkE,YAAlE,CADiB,IAEjB,KAAK,CAFV;AAIA,cAAM,KAAK,GAAG,QAAQ,CAAC,gBAAT,CACZ,QADY,EAEZ,SAAS,CAAC,IAAV,CAAe,KAFH,EAGZ,aAHY,CAAd;;AAMA,cAAI,KAAJ,EAAW;AACT,YAAA,SAAS,CAAC,IAAV,GAAiB;AAGf,cAAA,KAAK,EAAE,SAHQ;AAIf,cAAA,QAAQ,EAAA,QAJO;AAKf,cAAA,KAAK,EAAA;AALU,aAAjB;AAOD,WARD,MAQO;AACL,YAAA,0BAA0B,CAAC,SAAD,EAAY,cAAZ,CAA1B;AACD;;AAED,UAAA,cAAc,GAAG,OAAO,CAAC,KAAR,CAAc,cAAd,GAA4B,EAAA,GAAA,EAAA,EAC3C,EAAA,CAAC,cAAD,CAAA,GAAkB,aADyB,EAE3C,EAFe,EAAjB;AAID,SAvCD,MAuCO,IACL,QAAQ,CAAC,kBAAT,IACA,CAAC,aAAa,CAAC,CAAC,OAAD,EAAU,QAAV,CAAD,EAAsB,SAAtB,CAFT,EAGL;AACA,gBAAM,OAAI,CAAA,GAAJ,CAAI,QAAJ,KACJ,YADI,GACc,IAAA,cAAA,CAAc,CAAd,CADd,GAC4B,IAAQ,cAAR,CAC9B,oBAGA,cAHA,GAIF,OAJE,GAIF,IAAA,CAAA,SAAA,CAAA,MAAA,EAAA,IAAA,EAAA,CAAA,EAAA,SAAA,CAAA,CAAA,EAAA,GAAA,CALgC,CADlC;AAOD;AACF,OAvDD,MAuDO;AAEL,YAAM,QAAQ,GAAG,wBAAwB,CACvC,SADuC,EAEvC,OAAO,CAAC,WAF+B,CAAzC;;AAKA,YAAI,QAAQ,IAmBR,QAAQ,CAAC,eAAT,CAAyB,QAAzB,EAAmC,QAAnC,EAA6C,MAA7C,EAAqD,OAAO,CAAC,SAA7D,CAnBJ,EAmB6E;AAC3E,UAAA,QAAQ,CAAC,YAAT,CAAsB,UAAtB,CAAiC,OAAjC,CAAyC,OAAO,CAAC,GAAjD,EAAsD,OAAtD;AACD;AACF;AACF,KAxFD;;AA0FA,QAAI,aAAa,OAAO,MAAxB,EAAgC;AAC9B,UAAM,WAAS,GAAG,aAAa,CAAC,MAAD,CAA/B;;AAEA,UAAI,SAAS,CAAC,GAAV,CAAc,IAAlB,EAAwB;AACtB,QAAA,cAAc,GAAG,KAAK,WAAL,CAAiB,SAAjB,EAA4B,WAA5B,EAAuC,cAAvC,EAAuD,OAAvD,CAAjB;AACD;;AAED,UAAI,OAAO,CAAC,GAAR,CAAY,QAAZ,KAAyB,YAA7B,EAA2C;AACzC,YAAM,iBAAe,GAAG,UAAC,cAAD,EAAuB;AAC7C,iBAAA,yBAAuB,CAAC,GAAxB,CAA4B,sBAAsB,CAAC,cAAD,CAAlD,CAAA;AAAmE,SADrE;;AAEA,YAAM,yBAAuB,GAAG,IAAI,GAAJ,EAAhC;AACA,QAAA,OAAO,CAAC,OAAR,CAAgB,UAAA,SAAA,EAAS;AACvB,cAAI,OAAO,CAAC,SAAD,CAAP,IAAsB,SAAS,CAAC,YAApC,EAAkD;AAChD,YAAA,yBAAuB,CAAC,GAAxB,CAA4B,SAAS,CAAC,IAAV,CAAe,KAA3C;AACD;AACF,SAJD;;AAMA,YAAM,kBAAgB,GAAG,UAAC,cAAD,EAAuB;AAC9C,cAAM,SAAS,GAAG,SAAS,CAAC,GAAV,CAAc,GAAd,CAAkB,cAAlB,CAAlB;AACA,iBAAO,OAAO,CAAC,SAAS,IAAI,SAAS,CAAC,IAAvB,IAA+B,SAAS,CAAC,IAAV,CAAe,KAA/C,CAAd;AACD,SAHD;;AAKA,QAAA,MAAM,CAAC,IAAP,CAAY,cAAZ,EAA4B,OAA5B,CAAoC,UAAA,cAAA,EAAc;AAKhD,cAAI,iBAAe,CAAC,cAAD,CAAf,IACA,CAAC,kBAAgB,CAAC,cAAD,CADrB,EACuC;AACrC,YAAA,iBAAiB,CACf,WADe,EAEf,cAFe,EAGf,cAHe,EAIf,OAAO,CAAC,KAJO,CAAjB;AAMD;AACF,SAdD;AAeD;;AAED,MAAA,OAAO,CAAC,KAAR,CAAc,KAAd,CAAoB,MAApB,EAA4B,cAA5B;AAEA,aAAO,WAAP;AACD;;AAED,WAAO,cAAP;AACD,GA7MO;;AA+MA,EAAA,WAAA,CAAA,SAAA,CAAA,iBAAA,GAAR,UACE,KADF,EAEE,KAFF,EAGE,OAHF,EAIE,SAJF,EAIsB;AAJtB,QAAA,KAAA,GAAA,IAAA;;AAME,QAAI,CAAC,KAAK,CAAC,YAAP,IAAuB,KAAK,KAAK,IAArC,EAA2C;AAIzC,aAAO,OAAO,CAAC,GAAR,CAAY,QAAZ,KAAyB,YAAzB,GAAwC,KAAxC,GAAgD,SAAS,CAAC,KAAD,CAAhE;AACD;;AAED,QAAI,KAAK,CAAC,OAAN,CAAc,KAAd,CAAJ,EAA0B;AACxB,aAAO,KAAK,CAAC,GAAN,CAAU,UAAC,IAAD,EAAO,CAAP,EAAQ;AACvB,YAAM,KAAK,GAAG,KAAI,CAAC,iBAAL,CACZ,IADY,EACN,KADM,EACC,OADD,EACU,iBAAiB,CAAC,SAAD,EAAY,CAAZ,CAD3B,CAAd;;AAEA,QAAA,0BAA0B,CAAC,SAAD,EAAY,CAAZ,CAA1B;AACA,eAAO,KAAP;AACD,OALM,CAAP;AAMD;;AAED,WAAO,KAAK,mBAAL,CAAyB;AAC9B,MAAA,MAAM,EAAE,KADsB;AAE9B,MAAA,YAAY,EAAE,KAAK,CAAC,YAFU;AAG9B,MAAA,OAAO,EAAA,OAHuB;AAI9B,MAAA,SAAS,EAAA;AAJqB,KAAzB,CAAP;AAMD,GA5BO;;AA8BA,EAAA,WAAA,CAAA,SAAA,CAAA,WAAA,GAAR,UACE,SADF,EAEE,QAFF,EAGE,QAHF,EAIE,OAJF,EAKE,cALF,EAKwD;;;AALxD,QAAA,KAAA,GAAA,IAAA;;AAOE,QAAI,SAAS,CAAC,GAAV,CAAc,IAAd,IAAsB,CAAC,WAAW,CAAC,QAAD,CAAtC,EAAkD;AAChD,UAAM,GAAC,GAIL,CAAC,KAAK,CAAC,OAAN,CAAc,QAAd,CAAD,KAIC,WAAW,CAAC,QAAD,CAAX,IAAyB,uBAAuB,CAAC,QAAD,CAJjD,CAJ6C,GAS3C,QAT2C,GAShC,KAAK,CATpB;AAcA,UAAM,GAAC,GAAG,QAAV;;AAMA,UAAI,GAAC,IAAI,CAAC,cAAV,EAA0B;AACxB,QAAA,cAAc,GAAG,CAAC,WAAW,CAAC,GAAD,CAAX,GAAiB,GAAC,CAAC,KAAnB,GAA2B,GAA5B,CAAjB;AACD;;AAOD,UAAI,eAAJ;;AAEA,UAAM,UAAQ,GAAG,UACf,IADe,EAEf,IAFe,EAEM;AAErB,eAAO,KAAK,CAAC,OAAN,CAAc,IAAd,IACF,OAAO,IAAP,KAAgB,QAAhB,GAA2B,IAAI,CAAC,IAAD,CAA/B,GAAwC,KAAK,CAD3C,GAEH,OAAO,CAAC,KAAR,CAAc,aAAd,CAA4B,IAA5B,EAAkC,MAAM,CAAC,IAAD,CAAxC,CAFJ;AAGD,OAPD;;AASA,MAAA,SAAS,CAAC,GAAV,CAAc,OAAd,CAAsB,UAAC,SAAD,EAAY,cAAZ,EAA0B;AAC9C,YAAI,cAAJ,EAAoB;AAClB,UAAA,cAAc,CAAC,IAAf,CAAoB,cAApB;AACD;;AACD,YAAM,IAAI,GAAG,UAAQ,CAAC,GAAD,EAAI,cAAJ,CAArB;AACA,YAAM,IAAI,GAAG,UAAQ,CAAC,GAAD,EAAI,cAAJ,CAArB;;AACA,YAAM,IAAI,GAAG,KAAI,CAAC,WAAL,CACX,SADW,EAEX,IAFW,EAGX,IAHW,EAIX,OAJW,EAKX,cALW,CAAb;;AAOA,YAAI,IAAI,KAAK,IAAb,EAAmB;AACjB,UAAA,eAAa,GAAG,eAAa,IAAI,IAAI,GAAJ,EAAjC;AACA,UAAA,eAAa,CAAC,GAAd,CAAkB,cAAlB,EAAkC,IAAlC;AACD;;AACD,YAAI,cAAJ,EAAoB;AAClB,UAAA,SAAS,CAAC,cAAc,CAAC,GAAf,OAAyB,cAA1B,CAAT;AACD;AACF,OApBD;;AAsBA,UAAI,eAAJ,EAAmB;AAEjB,QAAA,QAAQ,GAAI,KAAK,CAAC,OAAN,CAAc,GAAd,IAAmB,GAAC,CAAC,KAAF,CAAQ,CAAR,CAAnB,GAA+B,QAAA,CAAA,EAAA,EAAM,GAAN,CAA3C;AACA,QAAA,eAAa,CAAC,OAAd,CAAsB,UAAC,KAAD,EAAQ,IAAR,EAAY;AAC/B,UAAA,QAAgB,CAAC,IAAD,CAAhB,GAAyB,KAAzB;AACF,SAFD;AAGD;AACF;;AAED,QAAI,SAAS,CAAC,IAAd,EAAoB;AAClB,aAAO,KAAK,KAAL,CAAW,QAAX,CAAoB,gBAApB,CACL,QADK,EAEL,QAFK,EAGL,SAAS,CAAC,IAHL,EAIL,OAJK,EAKL,cAAc,IAAI,CAAA,EAAA,GAAA,OAAO,CAAC,KAAR,EAAc,UAAd,CAAwB,KAAxB,CAAwB,EAAxB,EAA4B,cAA5B,CALb,CAAP;AAOD;;AAED,WAAO,QAAP;AACD,GA1FO;;AA2FV,SAAA,WAAA;AAAC,CA1YD,EAAA;;;AA4YA,IAAM,kBAAkB,GAAgB,EAAxC;;AAEA,SAAS,iBAAT,CACE,EADF,EAEE,IAFF,EAEuB;MADnB,GAAG,GAAA,EAAA,CAAA,G;;AAGL,MAAI,CAAC,GAAG,CAAC,GAAJ,CAAQ,IAAR,CAAL,EAAoB;AAClB,IAAA,GAAG,CAAC,GAAJ,CAAQ,IAAR,EAAc,kBAAkB,CAAC,GAAnB,MAA4B;AAAE,MAAA,GAAG,EAAE,IAAI,GAAJ;AAAP,KAA1C;AACD;;AACD,SAAO,GAAG,CAAC,GAAJ,CAAQ,IAAR,CAAP;AACD;;AAED,SAAS,0BAAT,CACE,EADF,EAEE,IAFF,EAEuB;MADnB,GAAG,GAAA,EAAA,CAAA,G;AAGL,MAAM,SAAS,GAAG,GAAG,CAAC,GAAJ,CAAQ,IAAR,CAAlB;;AACA,MAAI,SAAS,IACT,CAAC,SAAS,CAAC,IADX,IAEA,CAAC,SAAS,CAAC,GAAV,CAAc,IAFnB,EAEyB;AACvB,IAAA,kBAAkB,CAAC,IAAnB,CAAwB,SAAxB;AACA,IAAA,GAAG,CAAC,MAAJ,CAAW,IAAX;AACD;AACF;;AAED,IAAM,QAAQ,GAAG,IAAI,GAAJ,EAAjB;;AAIA,SAAS,iBAAT,CACE,WADF,EAEE,WAFF,EAGE,cAHF,EAIE,KAJF,EAIwB;AAEtB,MAAM,QAAQ,GAAG,UAAC,QAAD,EAAkC;AACjD,QAAM,KAAK,GAAG,KAAK,CAAC,aAAN,CAAiC,QAAjC,EAA2C,cAA3C,CAAd;AACA,WAAO,OAAO,KAAP,KAAiB,QAAjB,IAA6B,KAApC;AACD,GAHD;;AAKA,MAAM,QAAQ,GAAG,QAAQ,CAAC,WAAD,CAAzB;AACA,MAAI,CAAC,QAAL,EAAe;AAEf,MAAM,QAAQ,GAAG,QAAQ,CAAC,WAAD,CAAzB;AACA,MAAI,CAAC,QAAL,EAAe;AAIf,MAAI,WAAW,CAAC,QAAD,CAAf,EAA2B;AAI3B,MAAI,KAAK,CAAC,QAAD,EAAW,QAAX,CAAT,EAA+B;;AAK/B,MAAI,MAAM,CAAC,IAAP,CAAY,QAAZ,EAAsB,KAAtB,CACF,UAAA,GAAA,EAAG;AAAI,WAAA,KAAK,CAAC,aAAN,CAAoB,QAApB,EAA8B,GAA9B,MAAuC,KAAvC,CAAA;AAA6C,GADlD,CAAJ,EACyD;AACvD;AACD;;AAED,MAAM,UAAU,GACd,KAAK,CAAC,aAAN,CAA4B,WAA5B,EAAyC,YAAzC,KACA,KAAK,CAAC,aAAN,CAA4B,WAA5B,EAAyC,YAAzC,CAFF;AAGA,MAAM,SAAS,GAAG,sBAAsB,CAAC,cAAD,CAAxC;AACA,MAAM,WAAW,GAAM,UAAU,GAAA,GAAV,GAAc,SAArC;AAEA,MAAI,QAAQ,CAAC,GAAT,CAAa,WAAb,CAAJ,EAA+B;AAC/B,EAAA,QAAQ,CAAC,GAAT,CAAa,WAAb;AAEA,MAAM,cAAc,GAAa,EAAjC;;AAGA,MAAI,CAAC,KAAK,CAAC,OAAN,CAAc,QAAd,CAAD,IACA,CAAC,KAAK,CAAC,OAAN,CAAc,QAAd,CADL,EAC8B;AAC5B,KAAC,QAAD,EAAW,QAAX,EAAqB,OAArB,CAA6B,UAAA,KAAA,EAAK;AAChC,UAAM,QAAQ,GAAG,KAAK,CAAC,aAAN,CAAoB,KAApB,EAA2B,YAA3B,CAAjB;;AACA,UAAI,OAAO,QAAP,KAAoB,QAApB,IACA,CAAC,cAAc,CAAC,QAAf,CAAwB,QAAxB,CADL,EACwC;AACtC,QAAA,cAAc,CAAC,IAAf,CAAoB,QAApB;AACD;AACF,KAND;AAOD;;AAED,EAAA,OAAA,CAAA,GAAA,CAAU,QAAV,KACF,YADE,IACF,SAAA,CAAA,IAAA,CAAA,+CAA+E,SAA/E,GAA+E,cAA/E,GAA+E,UAA/E,GAA+E,6EAA/E,IAGuB,cAAA,CAAA,MAAA,GACjB,uCACE,cAAc,CAAC,IAAf,CAAoB,OAApB,CADF,GACiC,6CAFhB,GAGjB,EANN,IAMQ,yCANR,GAQE,WARF,GAQa,0EARb,GAWc,IAAI,CAAC,SAAL,CAAe,QAAf,EAAyB,KAAzB,CAA+B,CAA/B,EAAkC,IAAlC,CAXd,GAWqD,gBAXrD,GAYc,IAAI,CAAC,SAAL,CAAe,QAAf,EAAyB,KAAzB,CAA+B,CAA/B,EAAkC,IAAlC,CAZd,GAYqD,gRAZrD,CADE;AAoBD","sourcesContent":["import { SelectionSetNode, FieldNode, DocumentNode } from 'graphql';\nimport { invariant, InvariantError } from 'ts-invariant';\nimport { equal } from '@wry/equality';\n\nimport {\n  createFragmentMap,\n  FragmentMap,\n  getFragmentFromSelection,\n  getDefaultValues,\n  getFragmentDefinitions,\n  getOperationDefinition,\n  getTypenameFromResult,\n  makeReference,\n  isField,\n  resultKeyNameFromField,\n  StoreValue,\n  StoreObject,\n  Reference,\n  isReference,\n  shouldInclude,\n  hasDirectives,\n  cloneDeep,\n} from '../../utilities';\n\nimport { NormalizedCache, ReadMergeModifyContext, MergeTree } from './types';\nimport { makeProcessedFieldsMerger, fieldNameFromStoreName, storeValueIsStoreObject } from './helpers';\nimport { StoreReader } from './readFromStore';\nimport { InMemoryCache } from './inMemoryCache';\nimport { EntityStore } from './entityStore';\n\nexport interface WriteContext extends ReadMergeModifyContext {\n  readonly written: {\n    [dataId: string]: SelectionSetNode[];\n  };\n  readonly fragmentMap?: FragmentMap;\n  // General-purpose deep-merge function for use during writes.\n  merge<T>(existing: T, incoming: T): T;\n};\n\ninterface ProcessSelectionSetOptions {\n  dataId?: string,\n  result: Record<string, any>;\n  selectionSet: SelectionSetNode;\n  context: WriteContext;\n  mergeTree: MergeTree;\n}\n\nexport interface WriteToStoreOptions {\n  query: DocumentNode;\n  result: Object;\n  dataId?: string;\n  store: NormalizedCache;\n  variables?: Object;\n}\n\nexport class StoreWriter {\n  constructor(\n    public readonly cache: InMemoryCache,\n    private reader?: StoreReader,\n  ) {}\n\n  /**\n   * Writes the result of a query to the store.\n   *\n   * @param result The result object returned for the query document.\n   *\n   * @param query The query document whose result we are writing to the store.\n   *\n   * @param store The {@link NormalizedCache} used by Apollo for the `data` portion of the store.\n   *\n   * @param variables A map from the name of a variable to its value. These variables can be\n   * referenced by the query document.\n   *\n   * @return A `Reference` to the written object.\n   */\n  public writeToStore({\n    query,\n    result,\n    dataId,\n    store,\n    variables,\n  }: WriteToStoreOptions): Reference | undefined {\n    const operationDefinition = getOperationDefinition(query)!;\n    const merger = makeProcessedFieldsMerger();\n\n    variables = {\n      ...getDefaultValues(operationDefinition),\n      ...variables!,\n    };\n\n    const ref = this.processSelectionSet({\n      result: result || Object.create(null),\n      dataId,\n      selectionSet: operationDefinition.selectionSet,\n      mergeTree: { map: new Map },\n      context: {\n        store,\n        written: Object.create(null),\n        merge<T>(existing: T, incoming: T) {\n          return merger.merge(existing, incoming) as T;\n        },\n        variables,\n        varString: JSON.stringify(variables),\n        fragmentMap: createFragmentMap(getFragmentDefinitions(query)),\n      },\n    });\n\n    if (!isReference(ref)) {\n      throw new InvariantError(`Could not identify object ${JSON.stringify(result)}`);\n    }\n\n    // Any IDs written explicitly to the cache will be retained as\n    // reachable root IDs for garbage collection purposes. Although this\n    // logic includes root IDs like ROOT_QUERY and ROOT_MUTATION, their\n    // retainment counts are effectively ignored because cache.gc() always\n    // includes them in its root ID set.\n    store.retain(ref.__ref);\n\n    return ref;\n  }\n\n  private processSelectionSet({\n    dataId,\n    result,\n    selectionSet,\n    context,\n    // This object allows processSelectionSet to report useful information\n    // to its callers without explicitly returning that information.\n    mergeTree,\n  }: ProcessSelectionSetOptions): StoreObject | Reference {\n    const { policies } = this.cache;\n\n    // Identify the result object, even if dataId was already provided,\n    // since we always need keyObject below.\n    const [id, keyObject] = policies.identify(\n      result, selectionSet, context.fragmentMap);\n\n    // If dataId was not provided, fall back to the id just generated by\n    // policies.identify.\n    dataId = dataId || id;\n\n    if (\"string\" === typeof dataId) {\n      // Avoid processing the same entity object using the same selection\n      // set more than once. We use an array instead of a Set since most\n      // entity IDs will be written using only one selection set, so the\n      // size of this array is likely to be very small, meaning indexOf is\n      // likely to be faster than Set.prototype.has.\n      const sets = context.written[dataId] || (context.written[dataId] = []);\n      const ref = makeReference(dataId);\n      if (sets.indexOf(selectionSet) >= 0) return ref;\n      sets.push(selectionSet);\n\n      // If we're about to write a result object into the store, but we\n      // happen to know that the exact same (===) result object would be\n      // returned if we were to reread the result with the same inputs,\n      // then we can skip the rest of the processSelectionSet work for\n      // this object, and immediately return a Reference to it.\n      if (this.reader && this.reader.isFresh(\n        result,\n        ref,\n        selectionSet,\n        context,\n      )) {\n        return ref;\n      }\n    }\n\n    // This variable will be repeatedly updated using context.merge to\n    // accumulate all fields that need to be written into the store.\n    let incomingFields: StoreObject = Object.create(null);\n\n    // Write any key fields that were used during identification, even if\n    // they were not mentioned in the original query.\n    if (keyObject) {\n      incomingFields = context.merge(incomingFields, keyObject);\n    }\n\n    // If typename was not passed in, infer it. Note that typename is\n    // always passed in for tricky-to-infer cases such as \"Query\" for\n    // ROOT_QUERY.\n    const typename: string | undefined =\n      (dataId && policies.rootTypenamesById[dataId]) ||\n      getTypenameFromResult(result, selectionSet, context.fragmentMap) ||\n      (dataId && context.store.get(dataId, \"__typename\") as string);\n\n    if (\"string\" === typeof typename) {\n      incomingFields.__typename = typename;\n    }\n\n    const workSet = new Set(selectionSet.selections);\n\n    workSet.forEach(selection => {\n      if (!shouldInclude(selection, context.variables)) return;\n\n      if (isField(selection)) {\n        const resultFieldKey = resultKeyNameFromField(selection);\n        const value = result[resultFieldKey];\n\n        if (typeof value !== 'undefined') {\n          const storeFieldName = policies.getStoreFieldName({\n            typename,\n            fieldName: selection.name.value,\n            field: selection,\n            variables: context.variables,\n          });\n\n          const childTree = getChildMergeTree(mergeTree, storeFieldName);\n\n          let incomingValue =\n            this.processFieldValue(value, selection, context, childTree);\n\n          const childTypename = selection.selectionSet\n            && context.store.getFieldValue<string>(incomingValue as StoreObject, \"__typename\")\n            || void 0;\n\n          const merge = policies.getMergeFunction(\n            typename,\n            selection.name.value,\n            childTypename,\n          );\n\n          if (merge) {\n            childTree.info = {\n              // TODO Check compatibility against any existing\n              // childTree.field?\n              field: selection,\n              typename,\n              merge,\n            };\n          } else {\n            maybeRecycleChildMergeTree(mergeTree, storeFieldName);\n          }\n\n          incomingFields = context.merge(incomingFields, {\n            [storeFieldName]: incomingValue,\n          });\n\n        } else if (\n          policies.usingPossibleTypes &&\n          !hasDirectives([\"defer\", \"client\"], selection)\n        ) {\n          throw new InvariantError(\n            `Missing field '${resultFieldKey}' in ${JSON.stringify(\n              result,\n              null,\n              2,\n            ).substring(0, 100)}`,\n          );\n        }\n      } else {\n        // This is not a field, so it must be a fragment, either inline or named\n        const fragment = getFragmentFromSelection(\n          selection,\n          context.fragmentMap,\n        );\n\n        if (fragment &&\n            // By passing result and context.variables, we enable\n            // policies.fragmentMatches to bend the rules when typename is\n            // not a known subtype of the fragment type condition, but the\n            // result object contains all the keys requested by the\n            // fragment, which strongly suggests the fragment probably\n            // matched. This fuzzy matching behavior must be enabled by\n            // including a regular expression string (such as \".*\" or\n            // \"Prefix.*\" or \".*Suffix\") in the possibleTypes array for\n            // specific supertypes; otherwise, all matching remains exact.\n            // Fuzzy matches are remembered by the Policies object and\n            // later used when reading from the cache. Since there is no\n            // incoming result object to check when reading, reading does\n            // not involve the same fuzzy inference, so the StoreReader\n            // class calls policies.fragmentMatches without passing result\n            // or context.variables. The flexibility of fuzzy matching\n            // allows existing clients to accommodate previously unknown\n            // __typename strings produced by server/schema changes, which\n            // would otherwise be breaking changes.\n            policies.fragmentMatches(fragment, typename, result, context.variables)) {\n          fragment.selectionSet.selections.forEach(workSet.add, workSet);\n        }\n      }\n    });\n\n    if (\"string\" === typeof dataId) {\n      const entityRef = makeReference(dataId);\n\n      if (mergeTree.map.size) {\n        incomingFields = this.applyMerges(mergeTree, entityRef, incomingFields, context);\n      }\n\n      if (process.env.NODE_ENV !== \"production\") {\n        const hasSelectionSet = (storeFieldName: string) =>\n          fieldsWithSelectionSets.has(fieldNameFromStoreName(storeFieldName));\n        const fieldsWithSelectionSets = new Set<string>();\n        workSet.forEach(selection => {\n          if (isField(selection) && selection.selectionSet) {\n            fieldsWithSelectionSets.add(selection.name.value);\n          }\n        });\n\n        const hasMergeFunction = (storeFieldName: string) => {\n          const childTree = mergeTree.map.get(storeFieldName);\n          return Boolean(childTree && childTree.info && childTree.info.merge);\n        };\n\n        Object.keys(incomingFields).forEach(storeFieldName => {\n          // If a merge function was defined for this field, trust that it\n          // did the right thing about (not) clobbering data. If the field\n          // has no selection set, it's a scalar field, so it doesn't need\n          // a merge function (even if it's an object, like JSON data).\n          if (hasSelectionSet(storeFieldName) &&\n              !hasMergeFunction(storeFieldName)) {\n            warnAboutDataLoss(\n              entityRef,\n              incomingFields,\n              storeFieldName,\n              context.store,\n            );\n          }\n        });\n      }\n\n      context.store.merge(dataId, incomingFields);\n\n      return entityRef;\n    }\n\n    return incomingFields;\n  }\n\n  private processFieldValue(\n    value: any,\n    field: FieldNode,\n    context: WriteContext,\n    mergeTree: MergeTree,\n  ): StoreValue {\n    if (!field.selectionSet || value === null) {\n      // In development, we need to clone scalar values so that they can be\n      // safely frozen with maybeDeepFreeze in readFromStore.ts. In production,\n      // it's cheaper to store the scalar values directly in the cache.\n      return process.env.NODE_ENV === 'production' ? value : cloneDeep(value);\n    }\n\n    if (Array.isArray(value)) {\n      return value.map((item, i) => {\n        const value = this.processFieldValue(\n          item, field, context, getChildMergeTree(mergeTree, i));\n        maybeRecycleChildMergeTree(mergeTree, i);\n        return value;\n      });\n    }\n\n    return this.processSelectionSet({\n      result: value,\n      selectionSet: field.selectionSet,\n      context,\n      mergeTree,\n    });\n  }\n\n  private applyMerges<T extends StoreValue>(\n    mergeTree: MergeTree,\n    existing: StoreValue,\n    incoming: T,\n    context: ReadMergeModifyContext,\n    getStorageArgs?: Parameters<EntityStore[\"getStorage\"]>,\n  ): T {\n    if (mergeTree.map.size && !isReference(incoming)) {\n      const e: StoreObject | Reference | undefined = (\n        // Items in the same position in different arrays are not\n        // necessarily related to each other, so when incoming is an array\n        // we process its elements as if there was no existing data.\n        !Array.isArray(incoming) &&\n        // Likewise, existing must be either a Reference or a StoreObject\n        // in order for its fields to be safe to merge with the fields of\n        // the incoming object.\n        (isReference(existing) || storeValueIsStoreObject(existing))\n      ) ? existing : void 0;\n\n      // This narrowing is implied by mergeTree.map.size > 0 and\n      // !isReference(incoming), though TypeScript understandably cannot\n      // hope to infer this type.\n      const i = incoming as StoreObject | StoreValue[];\n\n      // The options.storage objects provided to read and merge functions\n      // are derived from the identity of the parent object plus a\n      // sequence of storeFieldName strings/numbers identifying the nested\n      // field name path of each field value to be merged.\n      if (e && !getStorageArgs) {\n        getStorageArgs = [isReference(e) ? e.__ref : e];\n      }\n\n      // It's possible that applying merge functions to this subtree will\n      // not change the incoming data, so this variable tracks the fields\n      // that did change, so we can create a new incoming object when (and\n      // only when) at least one incoming field has changed. We use a Map\n      // to preserve the type of numeric keys.\n      let changedFields: Map<string | number, StoreValue> | undefined;\n\n      const getValue = (\n        from: typeof e | typeof i,\n        name: string | number,\n      ): StoreValue => {\n        return Array.isArray(from)\n          ? (typeof name === \"number\" ? from[name] : void 0)\n          : context.store.getFieldValue(from, String(name))\n      };\n\n      mergeTree.map.forEach((childTree, storeFieldName) => {\n        if (getStorageArgs) {\n          getStorageArgs.push(storeFieldName);\n        }\n        const eVal = getValue(e, storeFieldName);\n        const iVal = getValue(i, storeFieldName);\n        const aVal = this.applyMerges(\n          childTree,\n          eVal,\n          iVal,\n          context,\n          getStorageArgs,\n        );\n        if (aVal !== iVal) {\n          changedFields = changedFields || new Map;\n          changedFields.set(storeFieldName, aVal);\n        }\n        if (getStorageArgs) {\n          invariant(getStorageArgs.pop() === storeFieldName);\n        }\n      });\n\n      if (changedFields) {\n        // Shallow clone i so we can add changed fields to it.\n        incoming = (Array.isArray(i) ? i.slice(0) : { ...i }) as T;\n        changedFields.forEach((value, name) => {\n          (incoming as any)[name] = value;\n        });\n      }\n    }\n\n    if (mergeTree.info) {\n      return this.cache.policies.runMergeFunction(\n        existing,\n        incoming,\n        mergeTree.info,\n        context,\n        getStorageArgs && context.store.getStorage(...getStorageArgs),\n      );\n    }\n\n    return incoming;\n  }\n}\n\nconst emptyMergeTreePool: MergeTree[] = [];\n\nfunction getChildMergeTree(\n  { map }: MergeTree,\n  name: string | number,\n): MergeTree {\n  if (!map.has(name)) {\n    map.set(name, emptyMergeTreePool.pop() || { map: new Map });\n  }\n  return map.get(name)!;\n}\n\nfunction maybeRecycleChildMergeTree(\n  { map }: MergeTree,\n  name: string | number,\n) {\n  const childTree = map.get(name);\n  if (childTree &&\n      !childTree.info &&\n      !childTree.map.size) {\n    emptyMergeTreePool.push(childTree);\n    map.delete(name);\n  }\n}\n\nconst warnings = new Set<string>();\n\n// Note that this function is unused in production, and thus should be\n// pruned by any well-configured minifier.\nfunction warnAboutDataLoss(\n  existingRef: Reference,\n  incomingObj: StoreObject,\n  storeFieldName: string,\n  store: NormalizedCache,\n) {\n  const getChild = (objOrRef: StoreObject | Reference): StoreObject | false => {\n    const child = store.getFieldValue<StoreObject>(objOrRef, storeFieldName);\n    return typeof child === \"object\" && child;\n  };\n\n  const existing = getChild(existingRef);\n  if (!existing) return;\n\n  const incoming = getChild(incomingObj);\n  if (!incoming) return;\n\n  // It's always safe to replace a reference, since it refers to data\n  // safely stored elsewhere.\n  if (isReference(existing)) return;\n\n  // If the values are structurally equivalent, we do not need to worry\n  // about incoming replacing existing.\n  if (equal(existing, incoming)) return;\n\n  // If we're replacing every key of the existing object, then the\n  // existing data would be overwritten even if the objects were\n  // normalized, so warning would not be helpful here.\n  if (Object.keys(existing).every(\n    key => store.getFieldValue(incoming, key) !== void 0)) {\n    return;\n  }\n\n  const parentType =\n    store.getFieldValue<string>(existingRef, \"__typename\") ||\n    store.getFieldValue<string>(incomingObj, \"__typename\");\n  const fieldName = fieldNameFromStoreName(storeFieldName);\n  const typeDotName = `${parentType}.${fieldName}`;\n  // Avoid warning more than once for the same type and field name.\n  if (warnings.has(typeDotName)) return;\n  warnings.add(typeDotName);\n\n  const childTypenames: string[] = [];\n  // Arrays do not have __typename fields, and always need a custom merge\n  // function, even if their elements are normalized entities.\n  if (!Array.isArray(existing) &&\n      !Array.isArray(incoming)) {\n    [existing, incoming].forEach(child => {\n      const typename = store.getFieldValue(child, \"__typename\");\n      if (typeof typename === \"string\" &&\n          !childTypenames.includes(typename)) {\n        childTypenames.push(typename);\n      }\n    });\n  }\n\n  invariant.warn(\n`Cache data may be lost when replacing the ${fieldName} field of a ${parentType} object.\n\nTo address this problem (which is not a bug in Apollo Client), ${\n  childTypenames.length\n    ? \"either ensure all objects of type \" +\n        childTypenames.join(\" and \") + \" have an ID or a custom merge function, or \"\n    : \"\"\n}define a custom merge function for the ${\n  typeDotName\n} field, so InMemoryCache can safely merge these objects:\n\n  existing: ${JSON.stringify(existing).slice(0, 1000)}\n  incoming: ${JSON.stringify(incoming).slice(0, 1000)}\n\nFor more information about these options, please refer to the documentation:\n\n  * Ensuring entity objects have IDs: https://go.apollo.dev/c/generating-unique-identifiers\n  * Defining custom merge functions: https://go.apollo.dev/c/merging-non-normalized-objects\n`);\n}\n"],"sourceRoot":""},"metadata":{},"sourceType":"module"}